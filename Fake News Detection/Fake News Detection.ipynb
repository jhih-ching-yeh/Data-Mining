{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Read data\n",
    "train = pd.read_csv(r\"D:\\data mining\\HW4\\train.csv\", sep = '\\t')\n",
    "test = pd.read_csv(r\"D:\\data mining\\HW4\\test.csv\", sep = '\\t')\n",
    "label = pd.read_csv(r\"D:\\data mining\\HW4\\sample_submission.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preprocessing\n",
    "train.text = train.text.str.lower()\n",
    "test.text = test.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# train data\n",
    "for i in range(4987):\n",
    "    # Tokenize\n",
    "    train.text[i] = tokenizer.tokenize(train.text[i])\n",
    "        \n",
    "    # Stemming\n",
    "    train.text[i] = \" \".join([porter_stemmer.stem(word = word) for word in train.text[i]])\n",
    "# test data\n",
    "for i in range(1247):\n",
    "    # Tokenize\n",
    "    test.text[i] = tokenizer.tokenize(test.text[i])\n",
    "        \n",
    "    # Stemming\n",
    "    test.text[i] = \" \".join([porter_stemmer.stem(word = word) for word in test.text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\葉之晴\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "EngStopWords = set(stopwords.words('english'))#這裡設定稍後取用 English 的停用詞語料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word to TfidfVec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = EngStopWords, token_pattern = \"(?u)\\\\b\\\\w+\\\\b\", smooth_idf = True, max_features = 10000)\n",
    "x_train = vectorizer.fit_transform(train.text).toarray()\n",
    "x_test = vectorizer.fit_transform(test.text).toarray()\n",
    "y_train = train.label\n",
    "y_test = label.label.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "from sklearn import metrics\n",
    "\n",
    "def Evaluation(y_test, prediction):\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, prediction))\n",
    "    print(\"Accuracy: \" , (metrics.accuracy_score(y_test, prediction)))\n",
    "    print(\"Precision: \" , (metrics.precision_score(y_test, prediction, pos_label = '1')))\n",
    "    print(\"Recall: \" , (metrics.recall_score(y_test, prediction, pos_label = '1')))\n",
    "    print(\"F-measure: \" , (metrics.f1_score(y_test, prediction, pos_label = '1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\dask\\config.py:131: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "D:\\anaconda\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[549  81]\n",
      " [526  91]]\n",
      "Accuracy:  0.5132317562149158\n",
      "Precision:  0.5290697674418605\n",
      "Recall:  0.14748784440842788\n",
      "F-measure:  0.23067173637515845\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGBoost_model = XGBClassifier(n_estimators = 100, max_features = 100, max_depth = 5, learning_rate = 0.1)\n",
    "XGBoost_model.fit(x_train, y_train)\n",
    "preds = XGBoost_model.predict(x_test)\n",
    "Evaluation(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[590  40]\n",
      " [581  36]]\n",
      "Accuracy:  0.5020048115477145\n",
      "Precision:  0.47368421052631576\n",
      "Recall:  0.05834683954619125\n",
      "F-measure:  0.10389610389610389\n"
     ]
    }
   ],
   "source": [
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBDT_model = GradientBoostingClassifier(n_estimators = 100, max_features = 100, max_depth = 5, learning_rate = 0.1)\n",
    "GBDT_model.fit(x_train, y_train)\n",
    "prediction = GBDT_model.predict(x_test)\n",
    "Evaluation(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Confusion Matrix:\n",
      "[[572  58]\n",
      " [537  80]]\n",
      "Accuracy:  0.5228548516439455\n",
      "Precision:  0.5797101449275363\n",
      "Recall:  0.12965964343598055\n",
      "F-measure:  0.2119205298013245\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "LightGBM_model = LGBMClassifier(n_estimators = 100, max_depth = 5, learning_rate = 0.1)\n",
    "LightGBM_model.fit(x_train, y_train)\n",
    "prediction = LightGBM_model.predict(x_test)\n",
    "Evaluation(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
